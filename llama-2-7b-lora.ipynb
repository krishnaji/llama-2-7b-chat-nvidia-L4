{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17848d39-18f2-49f0-b65c-51b470fc0168",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers \n",
    "!pip install accelerate\n",
    "!pip install bitsandbytes\n",
    "!pip install peft\n",
    "!pip install trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f2cb9-e364-4a69-a073-00597453af79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('gsm8k', 'main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1dd0cf-70ca-4176-aeea-934f4e98efb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset('gsm8k', 'main', split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4804a068-1ae6-4f8c-a407-b6b390cf7d8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0b66ac-e8d3-4e3b-ad98-5e221519d806",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import textwrap\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978a8147-db13-4f30-ac9d-ce671619c21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llama_chat_format(question : str,answer:str) -> str:\n",
    "    llama_template = textwrap.dedent(f\"\"\"\\\n",
    "    <s>[INST]\n",
    "    <<SYS>> You are helpful assistant. <<SYS>>\\n\n",
    "    Question: {question}\n",
    "    Answer: {answer}\n",
    "    [/INST] </s>\n",
    "    \"\"\")\n",
    "    return llama_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d13ff8-2bc1-415a-87c0-a9fcd69b357b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llama_chat_format(dataset[1]['question'],dataset[1]['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df12e7cb-39ed-498c-8b3c-1585428aa9cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "formatted_dataset=[]\n",
    "# Read all Q and A pairs and format them as llama chat instrunctions \n",
    "for example in range(len(dataset)):\n",
    "    formatted_dataset.append({\"text\":llama_chat_format(dataset[example]['question'],dataset[example]['answer'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b500c-907e-43e7-b5a2-cff497a5e9f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(0,2):\n",
    "    print(formatted_dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad49eb04-d9a6-4631-9edf-70df8a8687c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer,TrainingArguments,BitsAndBytesConfig\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b324e261-2a73-4ef9-adae-deaccb03ef94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quant_config  = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=False\n",
    ")\n",
    "\n",
    "peft_config= LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=8,\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736f17b5-728a-4311-83a7-e5edbfb7dd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donwload llama artifacts\n",
    "# mkdir llama2-7b-chat-hf\n",
    "# gs://vertex-model-garden-public-us-central1/llama2/llama2-7b-chat-hf llama2-7b-chat-hf/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbc26ab-9665-4c12-8e4c-9e7b293e183c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = '/home/jupyter/llama2-7b-chat-hf/llama2-7b-chat-hf'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,quantization_config=quant_config,device_map={\"\": 0} )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c3bf9e-c8ce-4975-b261-5563fe569a76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c943f96-8f54-4446-be02-254ccce3da04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f668b95-5aec-430d-8b7e-6727c7df588e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    logging_steps=25,\n",
    "    report_to=\"tensorboard\",\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=25,\n",
    "    lr_scheduler_type=\"constant\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1143d112-7dc7-438d-b295-00c0a85bcdce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset,Dataset\n",
    "import pandas as pd\n",
    "df=pd.DataFrame.from_dict(formatted_dataset)\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5009e29-60e6-447f-b385-6596311e8506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    train_dataset=dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    peft_config=peft_config,\n",
    "    args=training_args,\n",
    "    max_seq_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8973782-98c2-4dc5-a495-dd0bfbd637bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21981a22-aa97-40b7-aa4e-8a598cf1bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned=\"llama2-chat-tuned\"\n",
    "trainer.model.save_pretrained(tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19e3d8c-a091-4f54-a752-9f035152cc82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "query = \"Question: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May? Answer:\"\n",
    "generate_text = pipeline(task=\"text-generation\", model=\"llama2-chat-tuned\", tokenizer=tokenizer, max_length=4096)\n",
    "response = generate_text(f\"<s>[INST] {query} [/INST]\")\n",
    "print(response[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4280bf7-53cf-414f-bc7a-1ae1d943a32d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "log_dir = \"results/runs\"\n",
    "notebook.start(\"--logdir {} --port 8081\".format(log_dir))\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
